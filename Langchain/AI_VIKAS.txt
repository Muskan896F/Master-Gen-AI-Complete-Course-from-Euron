\documentclass[10pt, letterpaper]{article}

% Packages:
\usepackage[
    ignoreheadfoot, % set margins without considering header and footer
    top=2 cm, % separation between body and page edge from the top
    bottom=2 cm, % separation between body and page edge from the bottom
    left=2 cm, % separation between body and page edge from the left
    right=2 cm, % separation between body and page edge from the right
    footskip=1.0 cm, % separation between body and footer
    % showframe % for debugging
]{geometry} % for adjusting page geometry
\usepackage{titlesec} % for customizing section titles
\usepackage{tabularx} % for making tables with fixed width columns
\usepackage{array} % tabularx requires this
\usepackage[dvipsnames]{xcolor} % for coloring text
\definecolor{primaryColor}{RGB}{0, 0, 0} % define primary color
\usepackage{enumitem} % for customizing lists
\usepackage{fontawesome5} % for using icons
\usepackage{amsmath} % for math
\usepackage[
    pdftitle={Vikas Jangid's CV},
    pdfauthor={Vikas Jangid},
    pdfcreator={LaTeX with RenderCV},
    colorlinks=true,
    urlcolor=primaryColor
]{hyperref} % for links, metadata and bookmarks
\usepackage[pscoord]{eso-pic} % for floating text on the page
\usepackage{calc} % for calculating lengths
\usepackage{bookmark} % for bookmarks
\usepackage{lastpage} % for getting the total number of pages
\usepackage{changepage} % for one column entries (adjustwidth environment)
\usepackage{paracol} % for two and three column entries
\usepackage{ifthen} % for conditional statements
\usepackage{needspace} % for avoiding page brake right after the section title
\usepackage{iftex} % check if engine is pdflatex, xetex or luatex

% Ensure that generate pdf is machine readable/ATS parsable:
\ifPDFTeX
    \input{glyphtounicode}
    \pdfgentounicode=1
    \usepackage[T1]{fontenc}
    \usepackage[utf8]{inputenc}
    \usepackage{lmodern}
\fi

\usepackage{charter}

% Some settings:
\raggedright
\AtBeginEnvironment{adjustwidth}{\partopsep0pt} % remove space before adjustwidth environment
\pagestyle{empty} % no header or footer
\setcounter{secnumdepth}{0} % no section numbering
\setlength{\parindent}{0pt} % no indentation
\setlength{\topskip}{0pt} % no top skip
\setlength{\columnsep}{0.15cm} % set column separation
\pagenumbering{gobble} % no page numbering

\titleformat{\section}{\needspace{4\baselineskip}\bfseries\large}{}{0pt}{}[\vspace{1pt}\titlerule]

\titlespacing{\section}{
    % left space:
    -1pt
}{
    % top space:
    0.3 cm
}{
    % bottom space:
    0.2 cm
} % section title spacing

\renewcommand\labelitemi{$\vcenter{\hbox{\small$\bullet$}}$} % custom bullet points
\newenvironment{highlights}{
    \begin{itemize}[
        topsep=0.10 cm,
        parsep=0.10 cm,
        partopsep=0pt,
        itemsep=0pt,
        leftmargin=0 cm + 10pt
    ]
}{
    \end{itemize}
} % new environment for highlights


\newenvironment{highlightsforbulletentries}{
    \begin{itemize}[
        topsep=0.10 cm,
        parsep=0.10 cm,
        partopsep=0pt,
        itemsep=0pt,
        leftmargin=10pt
    ]
}{
    \end{itemize}
} % new environment for highlights for bullet entries

\newenvironment{onecolentry}{
    \begin{adjustwidth}{0 cm + 0.00001 cm}{0 cm + 0.00001 cm}
}{
    \end{adjustwidth}
} % new environment for one column entries

\newenvironment{twocolentry}[2][]{
    \onecolentry
    \def\secondColumn{#2}
    \setcolumnwidth{\fill, 4.5 cm}
    \begin{paracol}{2}
}{
    \switchcolumn \raggedleft \secondColumn
    \end{paracol}
    \endonecolentry
} % new environment for two column entries

\newenvironment{threecolentry}[3][]{
    \onecolentry
    \def\thirdColumn{#3}
    \setcolumnwidth{, \fill, 4.5 cm}
    \begin{paracol}{3}
    {\raggedright #2} \switchcolumn
}{
    \switchcolumn \raggedleft \thirdColumn
    \end{paracol}
    \endonecolentry
} % new environment for three column entries

\newenvironment{header}{
    \setlength{\topsep}{0pt}\par\kern\topsep\centering\linespread{1.5}
}{
    \par\kern\topsep
} % new environment for the header

\newcommand{\placelastupdatedtext}{% \placetextbox{<horizontal pos>}{<vertical pos>}{<stuff>}
  \AddToShipoutPictureFG*{% Add <stuff> to current page foreground
    \put(
        \LenToUnit{\paperwidth-2 cm-0 cm+0.05cm},
        \LenToUnit{\paperheight-1.0 cm}
    ){\vtop{{\null}\makebox[0pt][c]{
        \small\color{gray}\textit{Last updated in September 2024}\hspace{\widthof{Last updated in September 2024}}
    }}}%
  }%
}%

% save the original href command in a new command:
\let\hrefWithoutArrow\href

% new command for external links:
\newcommand{\externalLink}[2]{%
    \href{#1}{#2}%
}

\begin{document}
    \newcommand{\AND}{\unskip
        \cleaders\copy\ANDbox\hskip\wd\ANDbox
        \ignorespaces
    }
    \newsavebox\ANDbox
    \sbox\ANDbox{$|$}

\begin{header}
    \fontsize{25 pt}{25 pt}\selectfont Vikas Jangid

    \vspace{5 pt}

    \normalsize

    \kern 5.0 pt%
    \AND%
    \kern 5.0 pt%
    \externalLink{mailto:vikasjangidmk@gmail.com}{vikasjangidmk@gmail.com}%
    \kern 5.0 pt%
    \AND%
    \kern 5.0 pt%
    \externalLink{https://linkedin.com/in/vikas-jangid-ab0b0b1b9}{linkedin.com/in/vikas-jangid-ab0b0b1b9}%
    \kern 5.0 pt%
    \AND%
    \kern 5.0 pt%
    \externalLink{https://github.com/vikasjangidmk}{github.com/vikasjangidmk}%
\end{header}


    \vspace{5 pt - 0.3 cm}

\section{About Me}

\begin{onecolentry}
    "I’m an aspiring Data Scientist with a strong focus on Generative AI technologies, including experience with advanced models such as Llama3.3, Groq API, and NLP techniques. I have hands-on expertise in building and deploying AI-driven solutions for real-time document processing, semantic search, and content generation. During my recent internship, I gained hands-on experience in data cleaning, analysis, and visualization. I am now eager to apply my skills in a role that focuses on using data-driven insights to solve complex problems. I’m passionate about leveraging Generative AI to solve complex problems, enhance productivity, and create impactful solutions."
\end{onecolentry}

    \vspace{0.2 cm}


\section{Experience}

\begin{itemize}[leftmargin=0.5cm]
    \item[] \textbf{Data Science Intern} \hfill \textit{Sep--Oct 2024} \\
    Cognifyz, Remote
    \vspace{-0.2cm}
    \begin{itemize}[leftmargin=0.5cm]
        \item Conducted data cleaning and preprocessing to ensure the quality and reliability of datasets for analysis. 
        \item Utilized Python for data analysis and visualization, leveraging libraries such as \textbf{pandas}, \textbf{NumPy}, and \textbf{Matplotlib}.
        \item Designed and developed machine learning models for predictive analysis, evaluating their performance to generate actionable insights.
        \item Gained expertise in handling, analyzing, and building machine learning models for real-world applications, improving decision-making processes.
    \end{itemize}
    \vspace{0.3cm}

    \item[] \textbf{Data Science Intern} \hfill \textit{Dec 2024--Jan 2025} \\
    Oasis Info Byte, Remote
    \vspace{-0.2cm}
    \begin{itemize}[leftmargin=0.5cm]
        \item Leveraged advanced NLP techniques, such as lemmatization, stemming, and \textbf{word2vec}, to identify duplicate questions and improve user experience on the Quora platform.
        \item Implemented the \textbf{Random Forest} algorithm for classification tasks and integrated \textbf{Streamlit} to create an intuitive user interface for real-time interaction.
        \item Developed a machine learning-based system to identify defective semiconductor wafers, optimizing production efficiency and maintaining high-quality standards in integrated circuits.
        \item Applied advanced machine learning techniques to enhance defect detection accuracy in semiconductor manufacturing, improving operational efficiency.
    \end{itemize}
\end{itemize}

\section{Skills}

\begin{itemize}[leftmargin=0.15in]
    \item \textbf{Generative AI:}
    \begin{itemize}
        \item Prompt Design/Engineering
        \item Retrieval-Augmented Generation (RAG), Corrective RAG, Knowledge Graph-based RAG
        \item Fine-tuning (LORA/QLORA)
        \item Multi-agentic frameworks for RAG
        \item Experience with Generative AI tools like Groq API, Llama3.3
        \item Knowledge of Generative AI models, including GPT-based models and advanced techniques for content generation
    \end{itemize}
    \item \textbf{Programming Languages:} Python, SQL, MongoDB
    \item \textbf{Data Analysis:} NumPy, pandas, Matplotlib, seaborn
    \item \textbf{Machine Learning:} Supervised Learning, Unsupervised Learning, Recommendation Systems, NLP techniques (lemmatization, TF-IDF, word2vec)
    \item \textbf{Deep Learning:} ANN, CNN, RNN, LSTM, GRU, Transformers
    \item \textbf{Libraries:} scikit-learn, TensorFlow, Keras, NLTK, Gensim, spacy
    \item \textbf{Web API Development:} Flask, Streamlit, FastApi
    \item \textbf{Tools \& Technologies:} VS Code, Jupyter Notebook, Git, GitHub, Docker, MongoDB, MySQL Workbench
    \item \textbf{Other Skills:} Model deployment, working with APIs, End-to-End project handling
\end{itemize}



\section{Projects}

\begin{itemize}[leftmargin=0.15in]

    \item \textbf{RAG Applications with NVIDIA NeMo and Streamlit} \hfill 
    \textit{\href{https://github.com/vikasjangidmk/RAG1-NVIDIA-GENAI}{GitHub Link}} \\
    - Implemented a sophisticated Retrieval Augmented Generation (RAG) system leveraging NVIDIA's AI endpoints and Streamlit for document analysis and question-answering. \\
    - Developed a multi-PDF document processing pipeline with advanced text chunking and FAISS vector store integration. \\
    - Integrated real-time performance metrics and similarity search visualization for enhanced user experience. \\
    - Configured the system to support NVIDIA Llama-3.1-Nemotron-70b for context-aware responses and efficient query processing. \\
    - Optimized document chunking, vector search, and response generation to improve processing time and accuracy.

    \item \textbf{Reducing Operational Costs with Cost-Sensitive XGBoost-Based Failure Prediction} \hfill 
    \textit{\href{https://github.com/vikasjangidmk/Reducing-Operational-Costs-with-Cost-Sensitive-XG-Boost-Based-Failure-Prediction.git}{GitHub Link}} \\
    - This project focuses on handling imbalanced sensor data for classification tasks, with techniques such as data preprocessing, model evaluation, and cost analysis. \\
    - The dataset contains sensor data with missing values, class imbalance, and various features requiring imputation and scaling. \\
    - Several machine learning models, including Random Forest, XGBoost, and CatBoost, are evaluated using metrics such as accuracy, F1-score, precision, recall, and ROC-AUC score. \\
    - Advanced techniques such as KNN imputation, SMOTE-TOMEK for resampling, and robust scaling are used to improve model performance and handle data irregularities. \\
    - The project analyzes multiple experiments, comparing models' performance and costs, with the goal of identifying the most effective solution for imbalanced datasets.

    \item \textbf{AI-Driven Pneumonia Diagnosis: Harnessing Custom CNNs for Chest X-Ray Analysis} \hfill 
    \textit{\href{https://github.com/vikasjangidmk/AI-Driven-Pneumonia-Diagnosis-Harnessing-Custom-CNNs-for-Chest-X-ray-analysis.git}{GitHub Link}} \\
    - Developed a custom convolutional neural network (CNN) to detect pneumonia from chest X-ray images. \\
    - Achieved high diagnostic accuracy through rigorous training and validation processes. \\
    - Deployed the model in a user-friendly web application for healthcare professionals.

    \item \textbf{AI-Powered Voice Assistance Using Google's Gemini 1.5 Pro Model} \hfill 
    \textit{\href{https://github.com/vikasjangidmk/AI-Powered-Voice-Assistance}{GitHub Link}} \\
    - Built a voice assistant powered by Google's Gemini 1.5 Pro AI model, designed for engaging and efficient conversations. \\
    - Developed the application using Flask, enabling a web interface for handling voice inputs and providing real-time responses. \\
    - Configured the AI model via Google's Generative AI API, leveraging a customized prompt to ensure clear, concise, and contextually relevant answers. \\
    - Maintained conversation history using a global variable, allowing for context-aware responses and enhancing user experience. \\
    - Processed user queries through an API endpoint, generating dynamic responses and returning them alongside the conversation history. \\
    - Demonstrated effective integration of generative AI into a Flask web application, showcasing its potential for creating intelligent, user-focused conversational agents.

    \item \textbf{End-to-End Medical Chatbot Using Llama3.3} \hfill 
    \textit{\href{https://github.com/vikasjangidmk/End-to-End-Medical-Chatbot-Using-Llama3.3.git}{GitHub Link}} \\
    - Developed a robust medical chatbot powered by the Llama3.3 model to provide accurate and reliable healthcare information. \\
    - Designed to handle end-to-end interactions, including user query processing, response generation, and context management. \\
    - Implemented real-time query handling, context-aware conversation management, and precise medical responses leveraging Llama3.3's advanced language understanding capabilities. \\
    - Fine-tuned prompts to ensure professional, concise, and medically accurate answers tailored to user inquiries. \\
    - Incorporated a user-friendly interface, enabling seamless interaction for patients and healthcare professionals seeking quick and reliable medical information. \\
    - Demonstrated the potential of generative AI in healthcare, enhancing accessibility to medical knowledge while maintaining ethical and contextual considerations.

\end{itemize}


\section*{Certifications}

\begin{itemize}
    \item \textbf{Google Data Analytics} --- Coursera \\
    October 2024 \\
    Focused on data analysis techniques, data visualization, and cleaning.
    
    \item \textbf{Machine Learning and Deep Learning} --- Udemy \\
    July 2024 \\
    Covered algorithms, neural networks, and deep learning frameworks.
    
    \item \textbf{Complete GenAI Course with LangChain and HuggingFace} --- Udemy - September 2024 - Specialization in Generative AI, LangChain integration, and HuggingFace models.
\end{itemize}

\section{Education}

\begin{EducationEntry}
    \textbf{Master of Science in Data Science} \hfill 2023 - 2025 \\
    Chandigarh University, Chandigarh, India
    \begin{onecolentry}
        Key Courses: Machine Learning, Data Visualization, Big Data Analytics, Statistical Modeling \\
        Highlights: Academic projects focused on predictive analytics and real-world data solutions.
    \end{onecolentry}
\end{EducationEntry}

    \placelastupdatedtext
\end{document}
